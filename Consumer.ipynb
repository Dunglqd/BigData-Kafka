{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>switch</th>\n",
       "      <th>pktcount</th>\n",
       "      <th>bytecount</th>\n",
       "      <th>dur</th>\n",
       "      <th>dur_nsec</th>\n",
       "      <th>tot_dur</th>\n",
       "      <th>flows</th>\n",
       "      <th>packetins</th>\n",
       "      <th>pktperflow</th>\n",
       "      <th>...</th>\n",
       "      <th>pktrate</th>\n",
       "      <th>Pairflow</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>port_no</th>\n",
       "      <th>tx_bytes</th>\n",
       "      <th>rx_bytes</th>\n",
       "      <th>tx_kbps</th>\n",
       "      <th>rx_kbps</th>\n",
       "      <th>tot_kbps</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11425</td>\n",
       "      <td>1</td>\n",
       "      <td>45304</td>\n",
       "      <td>48294064</td>\n",
       "      <td>100</td>\n",
       "      <td>716000000</td>\n",
       "      <td>1.010000e+11</td>\n",
       "      <td>3</td>\n",
       "      <td>1943</td>\n",
       "      <td>13535</td>\n",
       "      <td>...</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>143928631</td>\n",
       "      <td>3917</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11605</td>\n",
       "      <td>1</td>\n",
       "      <td>126395</td>\n",
       "      <td>134737070</td>\n",
       "      <td>280</td>\n",
       "      <td>734000000</td>\n",
       "      <td>2.810000e+11</td>\n",
       "      <td>2</td>\n",
       "      <td>1943</td>\n",
       "      <td>13531</td>\n",
       "      <td>...</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3842</td>\n",
       "      <td>3520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11425</td>\n",
       "      <td>1</td>\n",
       "      <td>90333</td>\n",
       "      <td>96294978</td>\n",
       "      <td>200</td>\n",
       "      <td>744000000</td>\n",
       "      <td>2.010000e+11</td>\n",
       "      <td>3</td>\n",
       "      <td>1943</td>\n",
       "      <td>13534</td>\n",
       "      <td>...</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3795</td>\n",
       "      <td>1242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11425</td>\n",
       "      <td>1</td>\n",
       "      <td>90333</td>\n",
       "      <td>96294978</td>\n",
       "      <td>200</td>\n",
       "      <td>744000000</td>\n",
       "      <td>2.010000e+11</td>\n",
       "      <td>3</td>\n",
       "      <td>1943</td>\n",
       "      <td>13534</td>\n",
       "      <td>...</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3688</td>\n",
       "      <td>1492</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11425</td>\n",
       "      <td>1</td>\n",
       "      <td>90333</td>\n",
       "      <td>96294978</td>\n",
       "      <td>200</td>\n",
       "      <td>744000000</td>\n",
       "      <td>2.010000e+11</td>\n",
       "      <td>3</td>\n",
       "      <td>1943</td>\n",
       "      <td>13534</td>\n",
       "      <td>...</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3413</td>\n",
       "      <td>3665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104340</th>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>7742</td>\n",
       "      <td>81</td>\n",
       "      <td>842000000</td>\n",
       "      <td>8.184200e+10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15209</td>\n",
       "      <td>12720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104341</th>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>7742</td>\n",
       "      <td>81</td>\n",
       "      <td>842000000</td>\n",
       "      <td>8.184200e+10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15099</td>\n",
       "      <td>14693</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104342</th>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>3038</td>\n",
       "      <td>31</td>\n",
       "      <td>805000000</td>\n",
       "      <td>3.180500e+10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3409</td>\n",
       "      <td>3731</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104343</th>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>3038</td>\n",
       "      <td>31</td>\n",
       "      <td>805000000</td>\n",
       "      <td>3.180500e+10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15209</td>\n",
       "      <td>12720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104344</th>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>3038</td>\n",
       "      <td>31</td>\n",
       "      <td>805000000</td>\n",
       "      <td>3.180500e+10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15099</td>\n",
       "      <td>14693</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103839 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  switch  pktcount  bytecount  dur   dur_nsec       tot_dur  \\\n",
       "0       11425       1     45304   48294064  100  716000000  1.010000e+11   \n",
       "1       11605       1    126395  134737070  280  734000000  2.810000e+11   \n",
       "2       11425       1     90333   96294978  200  744000000  2.010000e+11   \n",
       "3       11425       1     90333   96294978  200  744000000  2.010000e+11   \n",
       "4       11425       1     90333   96294978  200  744000000  2.010000e+11   \n",
       "...       ...     ...       ...        ...  ...        ...           ...   \n",
       "104340   5262       3        79       7742   81  842000000  8.184200e+10   \n",
       "104341   5262       3        79       7742   81  842000000  8.184200e+10   \n",
       "104342   5262       3        31       3038   31  805000000  3.180500e+10   \n",
       "104343   5262       3        31       3038   31  805000000  3.180500e+10   \n",
       "104344   5262       3        31       3038   31  805000000  3.180500e+10   \n",
       "\n",
       "        flows  packetins  pktperflow  ...  pktrate  Pairflow  Protocol  \\\n",
       "0           3       1943       13535  ...      451         0         1   \n",
       "1           2       1943       13531  ...      451         0         1   \n",
       "2           3       1943       13534  ...      451         0         1   \n",
       "3           3       1943       13534  ...      451         0         1   \n",
       "4           3       1943       13534  ...      451         0         1   \n",
       "...       ...        ...         ...  ...      ...       ...       ...   \n",
       "104340      5         10          29  ...        0         0         2   \n",
       "104341      5         10          29  ...        0         0         2   \n",
       "104342      5         10          30  ...        1         0         2   \n",
       "104343      5         10          30  ...        1         0         2   \n",
       "104344      5         10          30  ...        1         0         2   \n",
       "\n",
       "        port_no   tx_bytes  rx_bytes  tx_kbps  rx_kbps  tot_kbps  label  \n",
       "0             3  143928631      3917        0      0.0       0.0      0  \n",
       "1             4       3842      3520        0      0.0       0.0      0  \n",
       "2             1       3795      1242        0      0.0       0.0      0  \n",
       "3             2       3688      1492        0      0.0       0.0      0  \n",
       "4             3       3413      3665        0      0.0       0.0      0  \n",
       "...         ...        ...       ...      ...      ...       ...    ...  \n",
       "104340        1      15209     12720        1      1.0       2.0      0  \n",
       "104341        3      15099     14693        1      1.0       2.0      0  \n",
       "104342        2       3409      3731        0      0.0       0.0      0  \n",
       "104343        1      15209     12720        1      1.0       2.0      0  \n",
       "104344        3      15099     14693        1      1.0       2.0      0  \n",
       "\n",
       "[103839 rows x 21 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "df = pd.read_csv('D:\\Code\\Personal\\BD_F\\dataset_sdn.csv')\n",
    "drop_col = ['src', 'dst']\n",
    "protocol_mapping = {'TCP': 0, 'UDP': 1, 'ICMP' : 2}\n",
    "df['Protocol'] = df['Protocol'].map(protocol_mapping)\n",
    "df = df.drop(drop_col, axis=1)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['label'],axis=1)\n",
    "y = df['label']\n",
    "# ms = MinMaxScaler()\n",
    "# x = ms.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden_Layer_1 (Dense)      (None, 28)                588       \n",
      "                                                                 \n",
      " Hidden_Layer_2 (Dense)      (None, 10)                290       \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 889 (3.47 KB)\n",
      "Trainable params: 889 (3.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(28 , input_shape=(20,) , activation=\"relu\" , name=\"Hidden_Layer_1\"))\n",
    "model.add(Dense(10 , activation=\"relu\" , name=\"Hidden_Layer_2\"))\n",
    "model.add(Dense(1 , activation=\"sigmoid\" , name=\"Output_Layer\"))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile( optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1368/1368 - 3s - loss: 0.3233 - accuracy: 0.8518 - val_loss: 0.2012 - val_accuracy: 0.9131 - 3s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "1368/1368 - 2s - loss: 0.1938 - accuracy: 0.9167 - val_loss: 0.1874 - val_accuracy: 0.9106 - 2s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "1368/1368 - 2s - loss: 0.1708 - accuracy: 0.9249 - val_loss: 0.1650 - val_accuracy: 0.9262 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "1368/1368 - 2s - loss: 0.1565 - accuracy: 0.9326 - val_loss: 0.1427 - val_accuracy: 0.9406 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "1368/1368 - 2s - loss: 0.1460 - accuracy: 0.9362 - val_loss: 0.1618 - val_accuracy: 0.9250 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "1368/1368 - 2s - loss: 0.1377 - accuracy: 0.9399 - val_loss: 0.1352 - val_accuracy: 0.9392 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "1368/1368 - 2s - loss: 0.1324 - accuracy: 0.9412 - val_loss: 0.1185 - val_accuracy: 0.9482 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "1368/1368 - 2s - loss: 0.1287 - accuracy: 0.9433 - val_loss: 0.1265 - val_accuracy: 0.9428 - 2s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "1368/1368 - 2s - loss: 0.1284 - accuracy: 0.9420 - val_loss: 0.1326 - val_accuracy: 0.9418 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "1368/1368 - 2s - loss: 0.1255 - accuracy: 0.9441 - val_loss: 0.1263 - val_accuracy: 0.9372 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "1368/1368 - 2s - loss: 0.1176 - accuracy: 0.9478 - val_loss: 0.1109 - val_accuracy: 0.9508 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "1368/1368 - 2s - loss: 0.1192 - accuracy: 0.9464 - val_loss: 0.1081 - val_accuracy: 0.9512 - 2s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "1368/1368 - 2s - loss: 0.1131 - accuracy: 0.9483 - val_loss: 0.1196 - val_accuracy: 0.9448 - 2s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "1368/1368 - 2s - loss: 0.1146 - accuracy: 0.9485 - val_loss: 0.1039 - val_accuracy: 0.9521 - 2s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "1368/1368 - 2s - loss: 0.1104 - accuracy: 0.9502 - val_loss: 0.1060 - val_accuracy: 0.9525 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "1368/1368 - 2s - loss: 0.1095 - accuracy: 0.9513 - val_loss: 0.1180 - val_accuracy: 0.9483 - 2s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "1368/1368 - 2s - loss: 0.1099 - accuracy: 0.9504 - val_loss: 0.1043 - val_accuracy: 0.9515 - 2s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "1368/1368 - 2s - loss: 0.1057 - accuracy: 0.9530 - val_loss: 0.1433 - val_accuracy: 0.9335 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "1368/1368 - 2s - loss: 0.1081 - accuracy: 0.9512 - val_loss: 0.0987 - val_accuracy: 0.9559 - 2s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "1368/1368 - 2s - loss: 0.1039 - accuracy: 0.9530 - val_loss: 0.1222 - val_accuracy: 0.9427 - 2s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "1368/1368 - 2s - loss: 0.1018 - accuracy: 0.9533 - val_loss: 0.1017 - val_accuracy: 0.9552 - 2s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "1368/1368 - 2s - loss: 0.0997 - accuracy: 0.9546 - val_loss: 0.0980 - val_accuracy: 0.9561 - 2s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "1368/1368 - 2s - loss: 0.1005 - accuracy: 0.9558 - val_loss: 0.1113 - val_accuracy: 0.9489 - 2s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "1368/1368 - 2s - loss: 0.1013 - accuracy: 0.9550 - val_loss: 0.0963 - val_accuracy: 0.9588 - 2s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "1368/1368 - 2s - loss: 0.0976 - accuracy: 0.9564 - val_loss: 0.0955 - val_accuracy: 0.9571 - 2s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "1368/1368 - 2s - loss: 0.0969 - accuracy: 0.9574 - val_loss: 0.0991 - val_accuracy: 0.9559 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "1368/1368 - 3s - loss: 0.0964 - accuracy: 0.9575 - val_loss: 0.1161 - val_accuracy: 0.9476 - 3s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "1368/1368 - 2s - loss: 0.0967 - accuracy: 0.9569 - val_loss: 0.0965 - val_accuracy: 0.9561 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "1368/1368 - 2s - loss: 0.0967 - accuracy: 0.9563 - val_loss: 0.1053 - val_accuracy: 0.9540 - 2s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "1368/1368 - 2s - loss: 0.0959 - accuracy: 0.9567 - val_loss: 0.1104 - val_accuracy: 0.9523 - 2s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "1368/1368 - 2s - loss: 0.0939 - accuracy: 0.9576 - val_loss: 0.0886 - val_accuracy: 0.9607 - 2s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "1368/1368 - 2s - loss: 0.0924 - accuracy: 0.9580 - val_loss: 0.0940 - val_accuracy: 0.9564 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "1368/1368 - 2s - loss: 0.0939 - accuracy: 0.9581 - val_loss: 0.0876 - val_accuracy: 0.9620 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "1368/1368 - 2s - loss: 0.0917 - accuracy: 0.9592 - val_loss: 0.0971 - val_accuracy: 0.9542 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "1368/1368 - 2s - loss: 0.0935 - accuracy: 0.9580 - val_loss: 0.1017 - val_accuracy: 0.9515 - 2s/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "1368/1368 - 2s - loss: 0.0924 - accuracy: 0.9582 - val_loss: 0.0879 - val_accuracy: 0.9627 - 2s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "1368/1368 - 2s - loss: 0.0918 - accuracy: 0.9589 - val_loss: 0.0947 - val_accuracy: 0.9586 - 2s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "1368/1368 - 2s - loss: 0.0911 - accuracy: 0.9599 - val_loss: 0.0870 - val_accuracy: 0.9598 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "1368/1368 - 2s - loss: 0.0909 - accuracy: 0.9584 - val_loss: 0.0891 - val_accuracy: 0.9598 - 2s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "1368/1368 - 2s - loss: 0.0888 - accuracy: 0.9601 - val_loss: 0.0838 - val_accuracy: 0.9622 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "1368/1368 - 2s - loss: 0.0886 - accuracy: 0.9593 - val_loss: 0.0882 - val_accuracy: 0.9616 - 2s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "1368/1368 - 2s - loss: 0.0907 - accuracy: 0.9596 - val_loss: 0.0891 - val_accuracy: 0.9605 - 2s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "1368/1368 - 2s - loss: 0.0856 - accuracy: 0.9620 - val_loss: 0.1079 - val_accuracy: 0.9527 - 2s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "1368/1368 - 2s - loss: 0.0868 - accuracy: 0.9616 - val_loss: 0.0825 - val_accuracy: 0.9641 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "1368/1368 - 2s - loss: 0.0847 - accuracy: 0.9621 - val_loss: 0.0838 - val_accuracy: 0.9633 - 2s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "1368/1368 - 2s - loss: 0.0851 - accuracy: 0.9618 - val_loss: 0.0891 - val_accuracy: 0.9607 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "1368/1368 - 2s - loss: 0.0891 - accuracy: 0.9603 - val_loss: 0.0919 - val_accuracy: 0.9582 - 2s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "1368/1368 - 2s - loss: 0.0843 - accuracy: 0.9620 - val_loss: 0.0875 - val_accuracy: 0.9612 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "1368/1368 - 2s - loss: 0.0852 - accuracy: 0.9616 - val_loss: 0.1728 - val_accuracy: 0.9373 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "1368/1368 - 2s - loss: 0.0842 - accuracy: 0.9624 - val_loss: 0.0858 - val_accuracy: 0.9629 - 2s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "1368/1368 - 2s - loss: 0.0839 - accuracy: 0.9629 - val_loss: 0.0856 - val_accuracy: 0.9626 - 2s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "1368/1368 - 2s - loss: 0.0848 - accuracy: 0.9630 - val_loss: 0.0907 - val_accuracy: 0.9604 - 2s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "1368/1368 - 2s - loss: 0.0864 - accuracy: 0.9614 - val_loss: 0.0823 - val_accuracy: 0.9643 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "1368/1368 - 2s - loss: 0.0820 - accuracy: 0.9626 - val_loss: 0.0901 - val_accuracy: 0.9612 - 2s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "1368/1368 - 2s - loss: 0.0819 - accuracy: 0.9631 - val_loss: 0.0980 - val_accuracy: 0.9548 - 2s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "1368/1368 - 2s - loss: 0.0842 - accuracy: 0.9627 - val_loss: 0.0852 - val_accuracy: 0.9623 - 2s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "1368/1368 - 2s - loss: 0.0814 - accuracy: 0.9639 - val_loss: 0.0886 - val_accuracy: 0.9623 - 2s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "1368/1368 - 2s - loss: 0.0826 - accuracy: 0.9635 - val_loss: 0.0878 - val_accuracy: 0.9628 - 2s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "1368/1368 - 2s - loss: 0.0820 - accuracy: 0.9627 - val_loss: 0.0811 - val_accuracy: 0.9631 - 2s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "1368/1368 - 2s - loss: 0.0817 - accuracy: 0.9636 - val_loss: 0.0797 - val_accuracy: 0.9655 - 2s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "1368/1368 - 2s - loss: 0.0787 - accuracy: 0.9646 - val_loss: 0.0898 - val_accuracy: 0.9584 - 2s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "1368/1368 - 2s - loss: 0.0805 - accuracy: 0.9641 - val_loss: 0.0890 - val_accuracy: 0.9635 - 2s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "1368/1368 - 2s - loss: 0.0823 - accuracy: 0.9634 - val_loss: 0.0908 - val_accuracy: 0.9567 - 2s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "1368/1368 - 2s - loss: 0.0817 - accuracy: 0.9633 - val_loss: 0.0890 - val_accuracy: 0.9596 - 2s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "1368/1368 - 2s - loss: 0.0795 - accuracy: 0.9645 - val_loss: 0.0805 - val_accuracy: 0.9659 - 2s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "1368/1368 - 2s - loss: 0.0784 - accuracy: 0.9646 - val_loss: 0.0854 - val_accuracy: 0.9639 - 2s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "1368/1368 - 2s - loss: 0.0807 - accuracy: 0.9645 - val_loss: 0.0929 - val_accuracy: 0.9610 - 2s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "1368/1368 - 2s - loss: 0.0790 - accuracy: 0.9656 - val_loss: 0.0875 - val_accuracy: 0.9655 - 2s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "1368/1368 - 2s - loss: 0.0796 - accuracy: 0.9645 - val_loss: 0.0826 - val_accuracy: 0.9638 - 2s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "1368/1368 - 2s - loss: 0.0791 - accuracy: 0.9655 - val_loss: 0.0788 - val_accuracy: 0.9668 - 2s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "1368/1368 - 2s - loss: 0.0776 - accuracy: 0.9658 - val_loss: 0.0792 - val_accuracy: 0.9652 - 2s/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "1368/1368 - 2s - loss: 0.0795 - accuracy: 0.9649 - val_loss: 0.0774 - val_accuracy: 0.9655 - 2s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "1368/1368 - 2s - loss: 0.0784 - accuracy: 0.9650 - val_loss: 0.0830 - val_accuracy: 0.9628 - 2s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "1368/1368 - 2s - loss: 0.0789 - accuracy: 0.9651 - val_loss: 0.0809 - val_accuracy: 0.9663 - 2s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "1368/1368 - 3s - loss: 0.0782 - accuracy: 0.9653 - val_loss: 0.1024 - val_accuracy: 0.9552 - 3s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "1368/1368 - 5s - loss: 0.0808 - accuracy: 0.9644 - val_loss: 0.0783 - val_accuracy: 0.9659 - 5s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "1368/1368 - 3s - loss: 0.0763 - accuracy: 0.9664 - val_loss: 0.0826 - val_accuracy: 0.9630 - 3s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "1368/1368 - 3s - loss: 0.0765 - accuracy: 0.9668 - val_loss: 0.0797 - val_accuracy: 0.9670 - 3s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "1368/1368 - 3s - loss: 0.0796 - accuracy: 0.9652 - val_loss: 0.0900 - val_accuracy: 0.9604 - 3s/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "1368/1368 - 3s - loss: 0.0758 - accuracy: 0.9670 - val_loss: 0.0828 - val_accuracy: 0.9641 - 3s/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "1368/1368 - 2s - loss: 0.0753 - accuracy: 0.9665 - val_loss: 0.0831 - val_accuracy: 0.9628 - 2s/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "1368/1368 - 2s - loss: 0.0762 - accuracy: 0.9666 - val_loss: 0.0783 - val_accuracy: 0.9663 - 2s/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "1368/1368 - 2s - loss: 0.0746 - accuracy: 0.9672 - val_loss: 0.0833 - val_accuracy: 0.9643 - 2s/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "1368/1368 - 3s - loss: 0.0748 - accuracy: 0.9671 - val_loss: 0.0810 - val_accuracy: 0.9644 - 3s/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "1368/1368 - 2s - loss: 0.0764 - accuracy: 0.9662 - val_loss: 0.0834 - val_accuracy: 0.9636 - 2s/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "1368/1368 - 3s - loss: 0.0749 - accuracy: 0.9664 - val_loss: 0.0852 - val_accuracy: 0.9626 - 3s/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "1368/1368 - 4s - loss: 0.0738 - accuracy: 0.9673 - val_loss: 0.0751 - val_accuracy: 0.9665 - 4s/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "1368/1368 - 4s - loss: 0.0742 - accuracy: 0.9675 - val_loss: 0.0847 - val_accuracy: 0.9614 - 4s/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "1368/1368 - 3s - loss: 0.0735 - accuracy: 0.9676 - val_loss: 0.0729 - val_accuracy: 0.9684 - 3s/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "1368/1368 - 3s - loss: 0.1291 - accuracy: 0.9429 - val_loss: 0.1320 - val_accuracy: 0.9399 - 3s/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "1368/1368 - 3s - loss: 0.1186 - accuracy: 0.9470 - val_loss: 0.1165 - val_accuracy: 0.9487 - 3s/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "1368/1368 - 2s - loss: 0.1106 - accuracy: 0.9504 - val_loss: 0.1107 - val_accuracy: 0.9501 - 2s/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "1368/1368 - 2s - loss: 0.0859 - accuracy: 0.9626 - val_loss: 0.1033 - val_accuracy: 0.9588 - 2s/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "1368/1368 - 2s - loss: 0.0774 - accuracy: 0.9659 - val_loss: 0.0800 - val_accuracy: 0.9668 - 2s/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "1368/1368 - 2s - loss: 0.0743 - accuracy: 0.9677 - val_loss: 0.0781 - val_accuracy: 0.9690 - 2s/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "1368/1368 - 3s - loss: 0.0738 - accuracy: 0.9676 - val_loss: 0.0760 - val_accuracy: 0.9687 - 3s/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "1368/1368 - 3s - loss: 0.0746 - accuracy: 0.9676 - val_loss: 0.0830 - val_accuracy: 0.9617 - 3s/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "1368/1368 - 4s - loss: 0.0712 - accuracy: 0.9685 - val_loss: 0.0950 - val_accuracy: 0.9612 - 4s/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "1368/1368 - 3s - loss: 0.0705 - accuracy: 0.9684 - val_loss: 0.0750 - val_accuracy: 0.9691 - 3s/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "1368/1368 - 2s - loss: 0.0875 - accuracy: 0.9634 - val_loss: 0.0809 - val_accuracy: 0.9661 - 2s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "history_org = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100, verbose=2,\n",
    "    callbacks=None,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0)\n",
    "DNN = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974/974 [==============================] - 1s 729us/step\n",
      "974/974 [==============================] - 1s 857us/step - loss: 33.0587 - accuracy: 0.4187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41872110962867737"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "y_pred = DNN.predict(MinMaxScaler().fit_transform(X_test))\n",
    "loss, accuracy = DNN.evaluate(MinMaxScaler().fit_transform(X_test), y_test)\n",
    "# metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf=SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "sgd_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(max_depth=5)\n",
    "DT.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf=SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "sgd_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;error&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;error&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='error', feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf=xgb.XGBClassifier(eval_metric = 'error',objective='binary:logistic',max_depth=2, learning_rate=0.1)\n",
    "xgb_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[1, 0, 1, 0]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[1, 0, 1, 0]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[1, 1, 1, 1]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 0, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[1, 0, 1, 0]\n",
      "\u001b[31mDDOS\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n",
      "[0, 0, 1, 0]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import socket\n",
    "from confluent_kafka import Consumer, KafkaError, KafkaException\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "from colorama import Fore, Style\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras import backend \n",
    "import keras\n",
    "import joblib\n",
    "\n",
    "def process(val):\n",
    "    df = pd.DataFrame([val])\n",
    "    protocol_mapping = {'TCP': 0, 'UDP': 1, 'ICMP' : 2}\n",
    "    df['Protocol'] = df['Protocol'].map(protocol_mapping)\n",
    "    x = df\n",
    "    \n",
    "    # pred1 = DNN.predict(x)\n",
    "    # pred1 = lr_clf.predict(x)\n",
    "\n",
    "    pred2 = DT.predict(x)\n",
    "\n",
    "    pred3 = svm.predict(x)\n",
    "\n",
    "    pred4 = xgb_clf.predict(x)\n",
    "\n",
    "    pred5 = knn_clf.predict(x)\n",
    "\n",
    "    # pred6 = sgd_clf.predict(x)\n",
    "\n",
    "    result = [pred5[0], pred2[0], pred3[0], pred4[0]]\n",
    "    # result = [pred1[0], pred2[0], pred3[0], pred4[0], pred5[0], pred6[0]]\n",
    "    print(result)\n",
    "    count = 0\n",
    "    for i in result: \n",
    "        if i == 1:\n",
    "            count +=1\n",
    "        if count >= 2:\n",
    "            print(Fore.RED + 'DDOS')\n",
    "            break\n",
    "    print(Style.RESET_ALL)\n",
    "\n",
    "\n",
    "def msg_process(msg):\n",
    "    val = msg.value()\n",
    "    try:\n",
    "        dval = json.loads(val)\n",
    "        process(dval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "def run_kafka_consumer():\n",
    "    conf = {'bootstrap.servers': 'localhost:9092',\n",
    "            'default.topic.config': {'auto.offset.reset': 'smallest'},\n",
    "            'group.id': socket.gethostname()}\n",
    "\n",
    "    consumer = Consumer(conf)\n",
    "    topic = 'Bigdata'\n",
    "    running = True\n",
    "\n",
    "    try:\n",
    "        while running:\n",
    "            consumer.subscribe([topic])\n",
    "            msg = consumer.poll(1)\n",
    "            if msg is None:\n",
    "                continue\n",
    "\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    print(f'Partition EOF: {msg.topic()} [{msg.partition()}] reached end at offset {msg.offset()}')\n",
    "                elif msg.error().code() == KafkaError.UNKNOWN_TOPIC_OR_PART:\n",
    "                    print(f'Topic unknown, creating {topic} topic')\n",
    "                elif msg.error():\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                msg_process(msg)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        consumer.close()\n",
    "\n",
    "run_kafka_consumer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
